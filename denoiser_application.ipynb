{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5024f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d753c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kspace_handling_functions import ifftnd,fftnd,rms_comb,do_image,plot_pair\n",
    "from plotting_functions import *\n",
    "from kspace_handling_functions import normalize_image,normalize_kspace_max,normalize_kspace_z,norm_dataset\n",
    "from data_transformation_and_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dc64d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.losses import SSIMLoss,MS_SSIMLoss\n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, beta=0.1, weight=None, size_average=True,SSIM_flag=False):\n",
    "        super(MixedLoss, self).__init__()\n",
    "        \n",
    "        self.pool2D=torch.nn.AvgPool2d([1,2],stride=[1,2],divisor_override=2)\n",
    "        \n",
    "        self.MSEloss = nn.MSELoss()\n",
    "        \n",
    "        if SSIM_flag == True :\n",
    "            self.im_loss = MS_SSIMLoss()\n",
    "            \n",
    "        else:\n",
    "            self.im_loss = nn.MSELoss()\n",
    "            \n",
    "        \n",
    "        \n",
    "        self.beta=beta\n",
    "        \n",
    " \n",
    "    def forward(self, k_pred,im_pred, targets):     \n",
    "        \n",
    "        z = self.pool2D(targets)# subsample\n",
    "        z = torch.complex(z[:,0,:,:], z[:,1,:,:])\n",
    "        #print(z.dtype)\n",
    "        z = torch.unsqueeze(z,dim=1)\n",
    "        #print(z.dtype)\n",
    "        im = torch.fft.fftshift( torch.fft.ifft2( torch.fft.ifftshift(z,dim=[-2,-1] ),norm=\"ortho\" ),dim=[-2,-1]).abs()\n",
    "\n",
    "        \n",
    "        #im=torch.nn.functional.normalize(im, p=2.0, dim=[0])# normalized GT image # controllare se va messo\n",
    "        #im_pred=torch.nn.functional.normalize(im_pred, p=2.0, dim=[0])# normalized prediction\n",
    "        \n",
    "        im_loss = self.im_loss(im_pred, im)\n",
    "        \n",
    "        k_loss = self.MSEloss(k_pred,targets)\n",
    "        \n",
    "        return (1-self.beta)*k_loss + self.beta*im_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb9ab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dipy in /opt/conda/lib/python3.8/site-packages (1.5.0)\n",
      "Requirement already satisfied: h5py>=2.8.0 in /opt/conda/lib/python3.8/site-packages (from dipy) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.1 in /opt/conda/lib/python3.8/site-packages (from dipy) (1.6.2)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in /opt/conda/lib/python3.8/site-packages (from dipy) (4.53.0)\n",
      "Requirement already satisfied: nibabel>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from dipy) (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.17.5; python_version == \"3.8\" in /opt/conda/lib/python3.8/site-packages (from h5py>=2.8.0->dipy) (1.20.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from nibabel>=3.0.0->dipy) (20.9)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from nibabel>=3.0.0->dipy) (59.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->nibabel>=3.0.0->dipy) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install dipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b18ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from dipy.denoise.nlmeans import nlmeans\n",
    "from dipy.denoise.noise_estimate import estimate_sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e4b40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Immagine = \"raw_sample.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248c34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normM(M0):\n",
    "    '''float norm tra 0.1'''\n",
    "    \n",
    "#    M0 = M0.numpy()\n",
    "    M0 = (M0-np.min(M0))/(np.max(M0)-np.min(M0))\n",
    "    return M0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c83f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_data = loadmat(Immagine)['ans']# output di scipy.io is a dictionary \"ans\" select the numerical data\n",
    "#imm = loadmat(Immagine)# output di scipy.io is a dictionary \"ans\" select the numerical data\n",
    "k_data=np.transpose(k_data,(-1,0,1))\n",
    "k_data = np.expand_dims(k_data,axis=1)\n",
    "\n",
    "k_data=normalize_kspace_max(k_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20dc0c",
   "metadata": {},
   "source": [
    "# transform data so it is similar to the taining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df377b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = list(k_data.shape)\n",
    "sp[1]=2\n",
    "nn_input = torch.zeros(sp)\n",
    "tt = ToTensor()\n",
    "for i,k in enumerate(k_data):\n",
    "    nn_input[i,:] = tt(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e486ffd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2, 64, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "800b85ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRDNet(\n",
       "  (upnet): UpNet(\n",
       "    (net): Sequential(\n",
       "      (0): Conv2d(2, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (1): BatchRenorm2d()\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(32, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (4): BatchRenorm2d()\n",
       "      (5): ReLU()\n",
       "      (6): Conv2d(32, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (7): BatchRenorm2d()\n",
       "      (8): ReLU()\n",
       "      (9): Conv2d(32, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (10): BatchRenorm2d()\n",
       "      (11): ReLU()\n",
       "      (12): Conv2d(32, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (13): BatchRenorm2d()\n",
       "      (14): ReLU()\n",
       "      (15): Conv2d(32, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (16): BatchRenorm2d()\n",
       "      (17): ReLU()\n",
       "      (18): Conv2d(32, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (19): BatchRenorm2d()\n",
       "      (20): ReLU()\n",
       "      (21): Conv2d(32, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (22): BatchRenorm2d()\n",
       "      (23): ReLU()\n",
       "      (24): Conv2d(32, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (25): BatchRenorm2d()\n",
       "      (26): ReLU()\n",
       "      (27): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (dwnet): DownNet(\n",
       "    (net): Sequential(\n",
       "      (0): Conv2d(2, 32, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "      (1): BatchRenorm2d()\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(32, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 2), dilation=(1, 2))\n",
       "      (4): ReLU()\n",
       "      (5): Conv2d(32, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 2), dilation=(1, 2))\n",
       "      (6): ReLU()\n",
       "      (7): Conv2d(32, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 2), dilation=(1, 2))\n",
       "      (8): ReLU()\n",
       "      (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (10): BatchRenorm2d()\n",
       "      (11): ReLU()\n",
       "      (12): Conv2d(32, 32, kernel_size=[3, 3], stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (13): ReLU()\n",
       "      (14): Conv2d(32, 32, kernel_size=[3, 3], stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (15): ReLU()\n",
       "      (16): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): BatchRenorm2d()\n",
       "      (18): ReLU()\n",
       "      (19): Conv2d(32, 2, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv2d(4, 2, kernel_size=[3, 7], stride=(1, 1), padding=(1, 3))\n",
       "  (last): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (subs): AvgPool2d(kernel_size=[1, 2], stride=[1, 2], padding=0)\n",
       "  (im1): freq2Image(\n",
       "    (subs): AvgPool2d(kernel_size=[1, 2], stride=[1, 2], padding=0)\n",
       "  )\n",
       "  (im2): freq2Image(\n",
       "    (subs): AvgPool2d(kernel_size=[1, 2], stride=[1, 2], padding=0)\n",
       "  )\n",
       "  (im_tot): freq2Image(\n",
       "    (subs): AvgPool2d(kernel_size=[1, 2], stride=[1, 2], padding=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import *\n",
    "#model = DnCNN(2,num_of_layers=model_params[\"layers\"],features = 32)\n",
    "model = BRDNet()\n",
    "# move the model into the GPU\n",
    "model.to('cpu')\n",
    "_ = model.load_state_dict(torch.load(\"new_model_exampe_normalized_beta05.pth\")['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1acdee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(nn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb30be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "102bfd7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3f7597c417a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_generator_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/giove/proton/plotting_functions.py\u001b[0m in \u001b[0;36mshow_generator_output\u001b[0;34m(sample_batched)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# convert them to numpy and then to complex so they can be used with do_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mk_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mk_label_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_label_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# to complex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mk_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1j\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "show_generator_output([nn_input,pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db1e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
